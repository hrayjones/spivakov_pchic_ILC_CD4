{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest import skip\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "import pybedtools\n",
    "import os\n",
    "from os import makedirs, error\n",
    "\n",
    "homedir = os.path.expanduser('~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ChicagoData.py\n",
    "Import and filter Chicago results\n",
    "\"\"\"\n",
    "\n",
    "from unittest import skip\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "import pybedtools\n",
    "import os\n",
    "from os import makedirs, error\n",
    "\n",
    "class ChicagoData(object):\n",
    "    \"\"\"Import CHiCAGO data\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 filename: str,\n",
    "                 drop_off_target_bait: bool = True,\n",
    "                 drop_off_target_oe: bool = True,\n",
    "                 drop_trans_chrom: bool = True,\n",
    "                 remove_p2p: bool= True,\n",
    "                 features_to_count: dict = {},\n",
    "                 gene_expression: str = \"\",\n",
    "                 nonzero_expression: bool = True,\n",
    "                 dropna_expression: bool = True,\n",
    "                 output_dir: str = \"\",\n",
    "                 output_basename: str = \"\",\n",
    "                 chain_file: str = \"\"\n",
    "                 ):\n",
    "        \"\"\"Initialize the object\n",
    "\n",
    "        This object will perform the following methods in order upon initialization:\n",
    "        \n",
    "        # Read file into DF\n",
    "        self._read_file_()\n",
    "        \n",
    "        # Format the DF\n",
    "        self._format_file_()\n",
    "        \n",
    "        # Filter the formatted DF\n",
    "        self._filter_file_()\n",
    "        \n",
    "        # Get the PIR df\n",
    "        self._get_PIR_df_()\n",
    "        \n",
    "        # Get the bait df\n",
    "        self._get_bait_df_()\n",
    "        \n",
    "        # Get the combined df\n",
    "        self._get_combined_df_()  \n",
    "        \n",
    "        # Get the feature counts per PIR and map to hg19\n",
    "        self._get_feature_counts_()\n",
    "        \n",
    "        # Import the gene expression matrix\n",
    "        self._import_gene_counts_()\n",
    "        \n",
    "        # Map the feature counts to genes in the expression matrix\n",
    "        self._map_feature_counts_to_genes_()\n",
    "        \n",
    "        # Map the ABC count or CHiCAGO count as a column in the gene expression matrix\n",
    "        self._map_ABC_counts_to_genes_()\n",
    "        \n",
    "        # Filter the gene expression matrix file\n",
    "        self._filter_expression_()\n",
    "        \n",
    "        # Get the PIR count v mean gene expression\n",
    "        self._get_PIR_count_v_mean_()\n",
    "        \n",
    "        # Write the newly formatted CHiCAGO data to a file\n",
    "        self._write_new_chicago_data_()\n",
    "        \n",
    "        Args:\n",
    "            filename (str): Input filename\n",
    "            drop_off_target_bait (bool, optional): Drop off target baits. Defaults to True.\n",
    "            drop_off_target_oe (bool, optional): Drop off target OE. Defaults to True.\n",
    "            drop_trans_chrom (bool, optional): Drop trans chromosomal interactions. Defaults to True.\n",
    "            remove_p2p (bool, optional): _description_. Defaults to True.\n",
    "            features_to_count (dict, optional): _description_. Defaults to {}.\n",
    "            gene_expression (str, optional): _description_. Defaults to \"\".\n",
    "            nonzero_expression (bool, optional): _description_. Defaults to True.\n",
    "            dropna_expression (bool, optional): _description_. Defaults to True.\n",
    "            output_dir (str, optional): _description_. Defaults to \"\".\n",
    "            output_basename (str, optional): _description_. Defaults to \"\".\n",
    "            chain_file (str, optional): Chain file for liftover of PIR bed files. Defaults to \"\".\n",
    "        \"\"\"\n",
    "        # Set filename to the input filename\n",
    "        self.filename = filename\n",
    "        # Set whether to drop off target baits\n",
    "        self.drop_off_target_bait = drop_off_target_bait\n",
    "        # Set whether to drop off target oe\n",
    "        self.drop_off_target_oe = drop_off_target_oe\n",
    "        # Set whether to drop transchromosomal interactions\n",
    "        self.drop_trans_chrom = drop_trans_chrom\n",
    "        # Remove promoter to promoter interactions\n",
    "        self.remove_p2p = remove_p2p\n",
    "        # Map feature counts to PIR if provided\n",
    "        self.features_to_count = features_to_count\n",
    "        # Import the gene expression matrix\n",
    "        self.gene_expression = gene_expression\n",
    "        # Only keep non-zero expression\n",
    "        self.nonzero_expression = nonzero_expression\n",
    "        # Drop na Values\n",
    "        self.dropna_expression = dropna_expression\n",
    "        # Set the output directory\n",
    "        self.output_dir = output_dir\n",
    "        # Set the output basename\n",
    "        self.basename = output_basename\n",
    "        # Set the chain file\n",
    "        self.chainfile = chain_file\n",
    "        \n",
    "        # Read file into DF\n",
    "        self._read_file_()\n",
    "        \n",
    "        # Format the DF\n",
    "        self._format_file_()\n",
    "        \n",
    "        # Filter the formatted DF\n",
    "        self._filter_file_()\n",
    "        \n",
    "        # Get the PIR df\n",
    "        self._get_PIR_df_()\n",
    "        \n",
    "        # Get the bait df\n",
    "        self._get_bait_df_()\n",
    "        \n",
    "        # Get the combined df\n",
    "        self._get_combined_df_()\n",
    "        \n",
    "        # Get the feature counts per PIR        \n",
    "        self._get_feature_counts_()\n",
    "        \n",
    "        # Import the gene expression matrix\n",
    "        self._import_gene_counts_()\n",
    "        \n",
    "        # Map the feature counts to genes in the expression matrix\n",
    "        self._map_feature_counts_to_genes_()\n",
    "        \n",
    "        # Filter the gene expression matrix file\n",
    "        self._filter_expression_()\n",
    "        \n",
    "        # Get the PIR count v mean gene expression\n",
    "        self._get_PIR_count_v_mean_()\n",
    "        \n",
    "        # Write the newly formatted CHiCAGO data to a file        \n",
    "        self._write_new_chicago_data_()        \n",
    "                    \n",
    "    def _read_file_(self):\n",
    "        \"\"\"Read in original file\n",
    "        \"\"\"\n",
    "        # Read in original file and save\n",
    "        self.input_df =  pd.read_csv(self.filename, sep=\"\\t\", header=0, low_memory=False)\n",
    "    \n",
    "    def _write_new_chicago_data_(self):\n",
    "        output_dir = os.path.join(self.output_dir, \"modified_chicago\")\n",
    "        \n",
    "        output_filename = os.path.join(output_dir, f\"{self.basename}_modified.tsv\")\n",
    "        \n",
    "        self._get_dir_(output_dir)\n",
    "\n",
    "        self.df.to_csv(output_filename, sep=\"\\t\", index=False)\n",
    "        \n",
    "    def _format_file_(self):\n",
    "        \"\"\"Format CHICAGO file\n",
    "        \"\"\"\n",
    "        # Create a copy of the raw input to be manipulated\n",
    "        df = self.input_df.copy()\n",
    "        \n",
    "        # Format the chromosome names\n",
    "        df[\"baitChr\"] = \"chr\" + df[\"baitChr\"].apply(str)\n",
    "        df[\"oeChr\"] = \"chr\" + df[\"oeChr\"].apply(str)\n",
    "        \n",
    "        # Create an ID column for the OE\n",
    "        df[\"oe_interval_ID\"] = df[\"oeChr\"] + \":\" + \\\n",
    "                   df[\"oeStart\"].apply(str) + \"-\" + \\\n",
    "                   df[\"oeEnd\"].apply(str)\n",
    "\n",
    "        # Create a bait ID column\n",
    "        df[\"bait_interval_ID\"] = df[\"baitChr\"] + \":\" + \\\n",
    "                   df[\"baitStart\"].apply(str) + \"-\" + \\\n",
    "                   df[\"baitEnd\"].apply(str)\n",
    "\n",
    "        # Create an interaction ID from the bait interval ID and the OE ID\n",
    "        df[\"interaction_ID\"] = df[\"bait_interval_ID\"] + \"_\" + df[\"oe_interval_ID\"].apply(str)\n",
    "        \n",
    "        # Find the bait ID from CHiCAGO\n",
    "        self.bait_ID = df[\"baitID\"].unique()\n",
    "        \n",
    "        # Find the unique OE ID\n",
    "        self.oe_ID = df[\"oeID\"].unique()\n",
    "\n",
    "        # Find the unique bait interval IDs\n",
    "        self.bait_interval_ID = df[\"bait_interval_ID\"].unique()\n",
    "        \n",
    "        # Find the unique OE ID\n",
    "        self.oe_interval_ID = df[\"oe_interval_ID\"].unique()\n",
    "        \n",
    "        self.df = df\n",
    "        \n",
    "    def _filter_file_(self):\n",
    "        \"\"\"Filter the formatted CHICAGO results\n",
    "        \"\"\"\n",
    "        # Drop the off target baits\n",
    "        if self.drop_off_target_bait:\n",
    "            self.df[self.df[\"baitName\"] != \"off_target\"]\n",
    "\n",
    "        # Drop the off target OE names\n",
    "        if self.drop_off_target_oe:\n",
    "            self.df[self.df[\"oeName\"] != \"off_target\"]\n",
    "\n",
    "        # Drop the trans chromosomal interactions\n",
    "        if self.drop_trans_chrom:\n",
    "            self.df = self.df[self.df[\"baitChr\"] == self.df[\"oeChr\"]]\n",
    "\n",
    "        # Drop promoter to promoter interactions\n",
    "        if self.remove_p2p:            \n",
    "            self.df = self.df[~self.df.oe_interval_ID.isin(self.bait_interval_ID)]\n",
    "        \n",
    "    def _get_PIR_df_(self):\n",
    "        \"\"\"Get a DF of all PIR interactions\n",
    "        \"\"\"\n",
    "        self.pir_df = self.df[[\"oeChr\", \"oeStart\", \"oeEnd\", \"oe_interval_ID\"]].drop_duplicates(subset=[\"oeChr\", \"oeStart\", \"oeEnd\"], keep=\"first\")\n",
    "        \n",
    "        self.PIR_bt = pybedtools.BedTool.from_dataframe(self.pir_df)\n",
    "\n",
    "    def _get_bait_df_(self):\n",
    "        \"\"\"Get a DF of baits\n",
    "        \"\"\"\n",
    "        self.bait_df = self.df[[\"baitChr\", \"baitStart\", \"baitEnd\", \"bait_interval_ID\"]].drop_duplicates(subset=[\"baitChr\", \"baitStart\", \"baitEnd\"], keep=\"first\")\n",
    "        \n",
    "    def _get_combined_df_(self):\n",
    "        \"\"\"Get a comined DF\n",
    "        \"\"\"\n",
    "        tmp_df = self.pir_df.copy()\n",
    "        tmp_df2 = self.bait_df.copy()\n",
    "\n",
    "        tmp_df.columns = [\"Chr\", \"Start\", \"Stop\", \"ID\"]\n",
    "        tmp_df2.columns = [\"Chr\", \"Start\", \"Stop\", \"ID\"]\n",
    "\n",
    "        self.unique_features = pd.concat([tmp_df, tmp_df2])\n",
    "    \n",
    "    def _get_feature_counts_(self):\n",
    "        \"\"\"Get the counts of features that overlap PIRs and map them back to the pcHiC interaction\n",
    "        \"\"\"\n",
    "        for file, tag in self.features_to_count.items():\n",
    "            print(f\"Importing {file} : Column will be saved as {tag}\")\n",
    "            output_intersection_dir = os.path.join(self.output_dir, \"PIR_intersection\")\n",
    "\n",
    "            output_intersection_fname = os.path.join(output_intersection_dir, f\"{self.basename}_PIR_intersect_{tag}.bed\")\n",
    "            \n",
    "            # Import and convert the featuers to a bedtools\n",
    "            feature_bt = pybedtools.BedTool(file)\n",
    "            \n",
    "            # Intersect the features to get counts\n",
    "            feature_counts = self.PIR_bt.intersect(feature_bt, c=True)\n",
    "            \n",
    "            # Intersect the features to get overlaps (true intersections)\n",
    "            feature_intersection = self.PIR_bt.intersect(feature_bt)\n",
    "            \n",
    "            feature_intersection_sort = feature_intersection.sort()\n",
    "            \n",
    "            # Convert bedtools to pandas\n",
    "            feature_counts_df = feature_counts.to_dataframe()\n",
    "                        \n",
    "            # Convert bedtools to dataframe\n",
    "            feature_intersection_df = feature_intersection_sort.to_dataframe()\n",
    "                        \n",
    "            # Create a dictionary of counts \n",
    "            counts_dict =  pd.Series(feature_counts_df[\"score\"].values,index=feature_counts_df[\"name\"]).to_dict()\n",
    "\n",
    "            # Map the counts back to the CHICAGO dataframe\n",
    "            self.df[tag] = self.df[\"oe_interval_ID\"].map(counts_dict)\n",
    "            \n",
    "            self._get_dir_(output_intersection_dir)\n",
    "            \n",
    "            feature_intersection_df[[\"chrom\", \"start\", \"end\"]].to_csv(output_intersection_fname, sep=\"\\t\", index=False, header=False)\n",
    "            \n",
    "            # Liftover the PIR files (here from hg38 to hg19)\n",
    "            if self.chainfile:\n",
    "                print(f\"Lifting over {tag} PIR intersections using {self.chainfile}\") \n",
    "                \n",
    "                liftover_dir = os.path.join(self.output_dir, \"PIR_intersection_liftover\")\n",
    "                \n",
    "                # Perform liftOver on the bedtools object \n",
    "                lifted = feature_intersection_sort.liftover(self.chainfile, unmapped=None) \n",
    "                \n",
    "                # Converted lifted coordinates to data frame\n",
    "                lifted_feature_intersection_df = lifted.to_dataframe()\n",
    "                \n",
    "                # Save the results\n",
    "                liftover_intersection_fname = os.path.join(liftover_dir, f\"{self.basename}_PIR_intersect_{tag}_hg19.bed\")\n",
    "                lifted_feature_intersection_df[[\"chrom\", \"start\", \"end\"]].to_csv(liftover_intersection_fname, sep=\"\\t\", index=False, header=False)\n",
    "\n",
    "    def _import_gene_counts_(self):\n",
    "        self.gene_counts = pd.read_csv(self.gene_expression, sep=\"\\t\", header=0, names=[\"GeneName\", \"Expression\"])\n",
    "        \n",
    "    def _map_feature_counts_to_genes_(self):\n",
    "        self.gene_counts[\"enhancer_count\"] = self.gene_counts[\"GeneName\"].map(self.df.groupby([\"baitName\"]).count()[\"baitChr\"])\n",
    "        \n",
    "        for _, tag in self.features_to_count.items():\n",
    "            self.gene_counts[f\"{tag}_count\"] = self.gene_counts[\"GeneName\"].map(self.df.groupby([\"baitName\"]).sum()[tag])\n",
    "\n",
    "    def _get_dir_(self, dir: str, permissions=0o0775, exist_ok : bool=True):\n",
    "        \"\"\"Makes a directory at the given location\n",
    "        Args:\n",
    "            dir (str): Path of the directory\n",
    "            permissions ([type], optional): Permissions of directory. Defaults to 0o0775.\n",
    "            exist_ok (bool, optional): If True, program will continue if directory exists. Defaults to True.\n",
    "        Returns:\n",
    "            str: Absolute path to the created directory\n",
    "            \n",
    "        Example:\n",
    "        \n",
    "        >>> output_dir = get_dir(\"./output/\")\n",
    "        \"\"\"\n",
    "        try:\n",
    "            makedirs(dir, mode=permissions)\n",
    "        except error:\n",
    "            if not exist_ok:\n",
    "                raise\n",
    "\n",
    "    def _filter_expression_(self):\n",
    "        output_analysis_dir = os.path.join(self.output_dir, \"expression_matrix\")\n",
    "\n",
    "        output_analysis_fname_unfiltered = os.path.join(output_analysis_dir, f\"{self.basename}_unfiltered_expression_matrix.tsv\")\n",
    "        output_analysis_fname_filtered = os.path.join(output_analysis_dir, f\"{self.basename}_filtered_expression_matrix.tsv\")\n",
    "\n",
    "        self._get_dir_(output_analysis_dir)\n",
    "\n",
    "        self.gene_counts.to_csv(output_analysis_fname_unfiltered, sep=\"\\t\", index=False)\n",
    "\n",
    "        if self.nonzero_expression:\n",
    "            self.gene_counts = self.gene_counts[self.gene_counts[\"Expression\"] > 0]\n",
    "\n",
    "        if self.dropna_expression:\n",
    "            self.gene_counts = self.gene_counts.dropna()\n",
    "\n",
    "        self.gene_counts[\"GeneName_MeanExpression\"] = self.gene_counts[\"GeneName\"] \\\n",
    "            + \" \" + self.gene_counts[\"Expression\"].apply(str)\n",
    "            \n",
    "        self.gene_counts.to_csv(output_analysis_fname_filtered, sep=\"\\t\", index=False)\n",
    "        \n",
    "    def _calculate_spearman_(self):\n",
    "        self.corr = []\n",
    "        output_analysis_dir = os.path.join(self.output_dir, \"correlation_analysis\")\n",
    "\n",
    "        output_analysis_fname = os.path.join(output_analysis_dir, f\"{self.basename}_correlation_stats.tsv\")\n",
    "             \n",
    "        for _, tag in self.features_to_count.items():\n",
    "            tmp_df = self.gene_counts[[f\"{tag}_count\", \"Expression\"]].copy()\n",
    "            \n",
    "            s_corr, s_pval = spearmanr(tmp_df[f\"{tag}_count\"], tmp_df[\"Expression\"])\n",
    "            \n",
    "            p_corr, p_pval = pearsonr(tmp_df[f\"{tag}_count\"], tmp_df[\"Expression\"])\n",
    "\n",
    "            self.corr.append([s_corr, s_pval, p_corr, p_pval, tag])\n",
    "\n",
    "        self.corr_df = pd.DataFrame(self.corr, columns=[\"Spearman_corr\", \"Spearman_pval\", \"Pearson_corr\", \"Pearson_pval\", \"Feature\"])\n",
    "            \n",
    "        self._get_dir_(output_analysis_dir)\n",
    "\n",
    "        self.corr_df.to_csv(output_analysis_fname, sep=\"\\t\", index=False)\n",
    "\n",
    "    def _get_PIR_count_v_mean_(self):\n",
    "        \"\"\"Create the dataframe of the number of features overlapping PIRs by mean gene expression\n",
    "        \n",
    "        First you groupby the feature counts column. Then you find all of the mean gene expression values\n",
    "        associated with the number of features overlapping a PIR. The output is a dataframe that can be plotted\n",
    "        \"\"\"\n",
    "    \n",
    "        for _, tag in self.features_to_count.items():\n",
    "            col_name = f\"{tag}_count\"\n",
    "            output_analysis_dir = os.path.join(self.output_dir, \"expression_analysis\")\n",
    "\n",
    "            output_analysis_fname = os.path.join(output_analysis_dir, f\"{self.basename}_{tag}.tsv\")\n",
    "            \n",
    "            # Create the dataframe\n",
    "            self.pir_count_v_mean = pd.DataFrame(self.gene_counts.groupby([col_name])[\"GeneName_MeanExpression\"].apply(list)).reset_index().explode(\"GeneName_MeanExpression\")\n",
    "        \n",
    "            self.pir_count_v_mean[col_name] = self.pir_count_v_mean[col_name].apply(int)\n",
    "            \n",
    "            self.pir_count_v_mean[[\"Gene_Name\", \"Mean_Gene_Expression\"]] = self.pir_count_v_mean[\"GeneName_MeanExpression\"].str.split(\" \", n=2, expand=True)\n",
    "            \n",
    "            self.pir_count_v_mean.drop(\"GeneName_MeanExpression\",axis=1, inplace=True)\n",
    "            \n",
    "            self.pir_count_v_mean[\"Mean_Gene_Expression\"] = self.pir_count_v_mean[\"Mean_Gene_Expression\"].apply(float)\n",
    "            \n",
    "            self._get_dir_(output_analysis_dir)\n",
    "\n",
    "            self._calculate_spearman_()\n",
    "            \n",
    "            self.pir_count_v_mean.to_csv(output_analysis_fname, sep=\"\\t\", index=False)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Chicago File: ILC3\n",
    "\n",
    "os.chdir(\"/rds/general/project/lms-spivakov-analysis/live/HRJ_monocytes/hILCs/RELI/spivakov_pchic_ILC_CD4\")\n",
    "\n",
    "input_file = \"./data/CHICAGO/hg38/inputs/ILC3_chicago_fres_5kb_abc_022_fres_extended_peakm.txt\"\n",
    "\n",
    "ilc3_file_dict = {\"./data/peaks/ATAC/ILC3_ATAC_peaks.bed\": \"ATAC\",\n",
    "                  \"./data/peaks/CHIP/ILC3_H3K27ac_peaks.bed\": \"H3K27ac\",\n",
    "                  \"./data/peaks/CHIP/ILC3_H3K4me3_peaks.bed\": \"H3K4me3\",\n",
    "                  \"./data/peaks/RE/ILC3_RE.bed\": \"RE\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing ./data/peaks/ATAC/ILC3_ATAC_peaks.bed : Column will be saved as ATAC\n",
      "Lifting over ATAC PIR intersections using ./data/genome_inf/hg38ToHg19.over.chain.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: which: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `which'\n",
      "sh: module: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `module'\n",
      "sh: scl: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `scl'\n",
      "sh: ml: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `ml'\n",
      "Reading liftover chains\n",
      "Mapping coordinates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing ./data/peaks/CHIP/ILC3_H3K27ac_peaks.bed : Column will be saved as H3K27ac\n",
      "Lifting over H3K27ac PIR intersections using ./data/genome_inf/hg38ToHg19.over.chain.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: which: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `which'\n",
      "sh: module: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `module'\n",
      "sh: scl: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `scl'\n",
      "sh: ml: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `ml'\n",
      "Reading liftover chains\n",
      "Mapping coordinates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing ./data/peaks/CHIP/ILC3_H3K4me3_peaks.bed : Column will be saved as H3K4me3\n",
      "Lifting over H3K4me3 PIR intersections using ./data/genome_inf/hg38ToHg19.over.chain.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: which: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `which'\n",
      "sh: module: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `module'\n",
      "sh: scl: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `scl'\n",
      "sh: ml: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `ml'\n",
      "Reading liftover chains\n",
      "Mapping coordinates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing ./data/peaks/RE/ILC3_RE.bed : Column will be saved as RE\n",
      "Lifting over RE PIR intersections using ./data/genome_inf/hg38ToHg19.over.chain.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: which: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `which'\n",
      "sh: module: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `module'\n",
      "sh: scl: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `scl'\n",
      "sh: ml: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `ml'\n",
      "Reading liftover chains\n",
      "Mapping coordinates\n"
     ]
    }
   ],
   "source": [
    "# Generate ChicagoData: ILC3\n",
    "\n",
    "ILC3_data = ChicagoData(input_file, \n",
    "                        drop_off_target_bait=True, \n",
    "                        drop_off_target_oe=True, \n",
    "                        drop_trans_chrom=True,\n",
    "                        remove_p2p=True,\n",
    "                        features_to_count=ilc3_file_dict,\n",
    "                        gene_expression=\"./data/RNA/ILC3_mean_expression.tsv\",\n",
    "                        output_dir=\"./data/outputs\",\n",
    "                        output_basename=\"ILC3_chicago_fres_5kb_abc_022_fres_extended_peakm.txt\",\n",
    "                        chain_file = \"./data/genome_inf/hg38ToHg19.over.chain.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Chicago File: CD4\n",
    "\n",
    "os.chdir(\"/rds/general/project/lms-spivakov-analysis/live/HRJ_monocytes/hILCs/RELI/spivakov_pchic_ILC_CD4\")\n",
    "\n",
    "input_file = \"./data/CHICAGO/hg38/inputs/CD4_chicago_fres_5kb_abc_02_fres_extended_peakm.txt\"\n",
    "\n",
    "cd4_file_dict = {\"./data/peaks/ATAC/CD4_ATAC_peaks.bed\": \"ATAC\",\n",
    "                  \"./data/peaks/CHIP/S008H1H1.ERX547940.H3K27ac.bwa.GRCh38.20150527.bed\": \"H3K27ac\",\n",
    "                  \"./data/peaks/CHIP/S008H1H1.ERX547958.H3K4me3.bwa.GRCh38.20150527.bed\": \"H3K4me3\",\n",
    "                  \"./data/peaks/RE/CD4_RE.bed\": \"RE\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing ./data/peaks/ATAC/CD4_ATAC_peaks.bed : Column will be saved as ATAC\n",
      "Lifting over ATAC PIR intersections using ./data/genome_inf/hg38ToHg19.over.chain.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: which: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `which'\n",
      "sh: module: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `module'\n",
      "sh: scl: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `scl'\n",
      "sh: ml: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `ml'\n",
      "Reading liftover chains\n",
      "Mapping coordinates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing ./data/peaks/CHIP/S008H1H1.ERX547940.H3K27ac.bwa.GRCh38.20150527.bed : Column will be saved as H3K27ac\n",
      "Lifting over H3K27ac PIR intersections using ./data/genome_inf/hg38ToHg19.over.chain.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: which: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `which'\n",
      "sh: module: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `module'\n",
      "sh: scl: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `scl'\n",
      "sh: ml: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `ml'\n",
      "Reading liftover chains\n",
      "Mapping coordinates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing ./data/peaks/CHIP/S008H1H1.ERX547958.H3K4me3.bwa.GRCh38.20150527.bed : Column will be saved as H3K4me3\n",
      "Lifting over H3K4me3 PIR intersections using ./data/genome_inf/hg38ToHg19.over.chain.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: which: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `which'\n",
      "sh: module: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `module'\n",
      "sh: scl: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `scl'\n",
      "sh: ml: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `ml'\n",
      "Reading liftover chains\n",
      "Mapping coordinates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing ./data/peaks/RE/CD4_RE.bed : Column will be saved as RE\n",
      "Lifting over RE PIR intersections using ./data/genome_inf/hg38ToHg19.over.chain.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: which: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `which'\n",
      "sh: module: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `module'\n",
      "sh: scl: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `scl'\n",
      "sh: ml: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `ml'\n",
      "Reading liftover chains\n",
      "Mapping coordinates\n"
     ]
    }
   ],
   "source": [
    "# Generate ChicagoData: CD4\n",
    "\n",
    "CD4_data = ChicagoData(input_file, \n",
    "                        drop_off_target_bait=True, \n",
    "                        drop_off_target_oe=True, \n",
    "                        drop_trans_chrom=True,\n",
    "                        remove_p2p=True,\n",
    "                        features_to_count=cd4_file_dict,\n",
    "                        gene_expression=\"./data/RNA/CD4_mean_expression.tsv\",\n",
    "                        output_dir=\"./data/outputs\",\n",
    "                        output_basename=\"CD4_chicago_fres_5kb_abc_02_fres_extended_peakm.txt\",\n",
    "                        chain_file = \"./data/genome_inf/hg38ToHg19.over.chain.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:enformer]",
   "language": "python",
   "name": "conda-env-enformer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
